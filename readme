https://github.com/ssbandjl/daos.git
git remote add upstream https://github.com/daos-stack/daos.git
git remote -v
git fetch upstream
git merge upstream/master

daos客户端支持s3(ds3): https://github.com/daos-stack/daos/commit/f848300590bcca29147256f84d6f766e7faa0457

git clone --recurse xxx
git submodule update --init --recursive

docker
Dockerfile.el.9
docker build --tag daos-base:rocky8.6 --build-arg DAOS_AUTH=no https://github.com/daos-stack/daos.git#master:utils/docker/vcluster/daos-base/el8
cp dockerfile to daos root
PREFIX=/opt/daos -> Install file: "build/release/gcc/src/control/daos" as "/opt/daos/bin/daos"

版本: utils/build.config


vscode filter:
*.c, *.h, readme, *sh, *.py, *.go


cart流程:
1. 日志初始化/注册协议和操作码 crt_init_opt
2. 创建上下文（fabric->domain->endpoint->cq...） crt_context_create
3. 创建请求 crt_req_create / crt_corpc_req_create RPC请求集合 传入目的端点 -> ep_rank
4. 发送请求（请求跟踪和取消跟踪） crt_req_send / dss_rpc_send
5. 查看请求进度和回调（progress和trigger） crt_progress
6. 发送回复 crt_reply_send / crt_reply_get



hg_example:
server:
main -> HG_Set_log_level -> HG_Init -> HG_Init_opt -> HG_Core_init_opt -> HG_Core_set_more_data_callback

crt_context_create -> ... ->  HG_Core_init_opt -> hg_core_init -> NA_Initialize_opt -> na_info_parse 解析网络抽象信息 -> na_class_table -> check_protocol 检查协议 -> initialize 初始化 -> na_ofi_initialize 网络抽象初始化 -> na_ofi_check_interface 检查接口(getaddrinfo/getifaddrs/inet_ntop) -> HG_QUEUE_INIT(&priv->addr_pool) 初始化地址池 -> na_ofi_domain_open 打开域 -> na_ofi_getinfo 先查看信息 -> fi_fabric/fi_domain 分配保护域数据 ibv_alloc_pd -> hg_mem_pool_create 创建内存池 -> na_ofi_addr_create 创建地址,设置长度,放入地址池 -> na_ofi_endpoint_resolve_src_addr -> fi_getname -> vrb_dgram_ep_getname ->  
na_ofi_get_uri -> fi_av_straddr -> char *ofi_straddr -> na_ofi_addr_ht_lookup 查找或插入 -> src_addr = na_ofi_addr 设置端点源地址

fi_av_insert 将地址插入到地址向量




查池 ... -> ds_pool_query_handler -> pool_space_query_bcast -> bcast_create -> ds_pool_bcast_create -> crt_corpc_req_create -> crt_corpc_info_init 集体rpc初始化 -> crp_coll = 1 -> ...
 
crt_req_send -> crt_corpc_req_hdlr rpc请求集合控制器 -> co_pre_forward 转发前执行, 比如 ds_mgmt_tgt_map_update_pre_forward -> crt_tree_get_children -> crt_req_create_internal 创建N个内部请求 for (i = 0; i < co_info->co_child_num; i++) -> corpc_add_child_rpc 添加子rpc -> crt_req_send 回调(crt_corpc_reply_hdlr) 先发子RPC -> crt_rpc_common_hdlr  -> 发送后执行回调 crt_hg_req_send_cb -> 执行回调 crp_complete_cb -> crt_corpc_reply_hdlr

发送后
接收方(目标rank): crt_rpc_handler_common -> crt_corpc_common_hdlr -> crt_bulk_create -> crt_bulk_transfer -> 完成回调 crt_corpc_chained_bulk_cb -> crt_corpc_initiate 发起集体rpc -> crt_corpc_info_init -> crt_corpc_req_hdlr



corpc_add_child_rpc -> 继承父rpc部分属性 -> 将rpc插入co_child_rpcs尾部 -> 

map_update
ds_mgmt_tgt_map_update_pre_forward -> ds_mgmt_group_update


crt_tree_get_children -> CRT_TREE_PARAMETER_CHECKING -> crt_get_filtered_grp_rank_list 获取target组 -> to_get_children_cnt -> crt_knomial_get_children_cnt -> 


crt_corpc_reply_hdlr -> crt_corpc_complete

crt_corpc_reply_hdlr -> 


crt_corpc_req_hdlr -> 

SHIFT: 移位运算

树:
branch_ratio – 分支比率，对于 CRT_TREE_FLAT 被忽略。 对于 KNOMIAL 树或 KARY 树，有效值应在 [CRT_TREE_MIN_RATIO, CRT_TREE_MAX_RATIO] 范围内，否则将被视为无效参数
grp_rank_list 是用于构建树的目标组（在应用 filter_ranks 之后），其中的排名号用于主要组





rsvc_hash


Put a replicated service reference: 放置一个复制的服务参考

停止 RDB 副本数据库。 db 中的所有 TX 必须已经结束或仅在 rdb 中阻塞。


filter_invert: 倒置过滤

docker build  . -f utils/docker/Dockerfile.centos.7 -t daos:2.0.1

curl -sSfL --retry 10 --retry-max-time 60 -o ofi_patch_001 https://raw.githubusercontent.com/daos-stack/libfabric/master/daos-9173-ofi.patch
curl -sSfL --retry 10 --retry-max-time 60 -o ofi_patch_002 https://raw.githubusercontent.com/daos-stack/libfabric/master/daos-9376-ofi.patch
/home/daos/pre/build/external/release/ofi_patch_001

/home/daos/cache/patch/ofi_patch_001

resolve_patches


➜  daos git:(heads/v2.0.1) ✗ docker --version
Docker version 20.10.12, build e91ed57

online:
cd /root/github/storage/daos/docker
docker build https://github.com/daos-stack/daos.git\#v2.0.1 -f utils/docker/Dockerfile.centos.7 -t daos

local_tree:
git clone --recurse-submodules https://github.com/daos-stack/daos.git -b v2.0.1
docker build  . -f utils/docker/Dockerfile.centos.7 -t daos


docker stop server && docker rm server
docker run -it -d --privileged --cap-add=ALL --name server -v /root/github/storage/daos/origin/docker:/home/daos/docker -v /dev:/dev -v /dev/hugepages:/dev/hugepages -v /sys/fs/cgroup:/sys/fs/cgroup:ro daos:2.0.1

docker run -it -d --privileged --cap-add=ALL --name daos1 -v /root/project/stor/daos/main/daos:/home/daos -v /dev:/dev -v /dev/hugepages:/dev/hugepages -v /sys/fs/cgroup:/sys/fs/cgroup:ro daos:almalinux9


docker run -it -d --privileged --cap-add=ALL --name daos1 -v /root/github/storage/daos/origin/docker:/root/github/storage/daos/origin/docker -v /dev:/dev -v /dev/hugepages:/dev/hugepages -v /sys/fs/cgroup:/sys/fs/cgroup:ro daos:2.0.1

docker run -it -d --privileged --cap-add=ALL --name daos2  -p 22223:22 -p 31436:31416 -v /root/github/storage/daos/origin/docker:/home/daos/docker -v /dev:/dev -v /dev/hugepages:/dev/hugepages -v /sys/fs/cgroup:/sys/fs/cgroup:ro daos:2.0.1

docker run -it -d --privileged --cap-add=ALL --name centos  -p 22222:22 -p 5555:5555 -v /root/project/stor/ceph/xb/docker/ceph:/root/project/stor/ceph/xb/docker/ceph 

/root/project/stor/ceph/xb/docker/ceph

61:
docker run -it -d --privileged --cap-add=ALL --name daos1 -v /home/xb/project/stor/daos/origin/docker/daos:/home/xb/project/stor/daos/origin/docker/daos -v /dev:/dev -v /dev/hugepages:/dev/hugepages -v /sys/fs/cgroup:/sys/fs/cgroup:ro daos:2.0.1
docker exec -u root -it daos1 bash -c 'cd /home/daos;exec "${SHELL:-sh}"'


docker exec -it -u root server /bin/bash
export FI_LOG_LEVEL=debug
daos_server start -o /home/daos/daos/utils/config/examples/daos_server_local.yml

拷贝配置文件:
echo 'export PATH=/opt/daos/bin:$PATH' >> /root/.bashrc
mkdir -p /opt/daos/etc/
mkdir -p /etc/daos/certs
rm -f /opt/daos/etc/*.yml && cp utils/config/*.yml /opt/daos/etc/ && cp -r utils/config/examples/certs /etc/daos/
source /root/.bashrc

改权限:
chmod 0700 /etc/daos/certs/agent.key
chmod 0700 /etc/daos/certs/server.key
chmod 0700 /etc/daos/certs/admin.key


dmg sto scan
dmg net scan
dmg -i storage format
dmg storage format

dmg system erase

# -e TZ=Asia/Shanghai
docker run -it -d --privileged --cap-add=ALL --name server -v /dev:/dev -v /dev/hugepages:/dev/hugepages daos
docker exec server daos_server start -o /home/daos/daos/utils/config/examples/daos_server_local.yml
docker exec server dmg -i storage format

daos1(){
	
  docker exec -u root -it daos bash -c 'cd /root/github/storage/daos/origin/docker/daos;exec "${SHELL:-sh}"'
}

vim /home/daos/daos/utils/config/examples/daos_server_local.yml
- D_LOG_MASK=DEBUG
- DD_SUBSYS=all
- DD_MASK=all


教程:
tour.md
创建池/创建容器
dmg system query -v
dmg pool create sxb -z 4g  #dmg pool create --scm-size=8G --nvme-size=64G --label=samirrav_pool -u samirrav@, dmg pool create --scm-size=8G --nvme-size=64G samirrav_pool -u samirrav@ -g samirrav@
dmg pool list -v
dmg pool query sxb
daos cont create --oclass=RP_3GX --properties=rf:1 --type POSIX --pool sxb --label sxb
daos container create --pool sxb --type POSIX --label sxb
daos container --verbose query -p sxb -c sxb
daos container create sxb --type POSIX sxb #### 2.3, daos [OPTIONS] container create [create-OPTIONS] [pool label or UUID] [label]
daos container query sxb sxb --verbose

systemd
$ cat ~/.config/systemd/user/samirrav_dfuse.service
[Service]
ExecStart=dfuse  --foreground -m /scratch_fs/samirrav_dfuse/  --pool samirrav_pool --cont samirrav_cont
ExecStop=fusermount3 -u /scratch_fs/samirrav_dfuse/
[Install]
WantedBy=default.target
$
$ systemctl --user daemon-reload
$ systemctl --user list-unit-files | grep samirrav


查池
[root@e65332746210 daos]# dmg pool query sxb
Pool 9b6324da-f57a-4cd7-9586-989e9259f60e, ntarget=1, disabled=0, leader=0, version=1
Pool space info:
- Target(VOS) count:1
- Storage tier 0 (SCM):
  Total size: 240 MB
  Free: 240 MB, min:240 MB, max:240 MB, mean:240 MB
- Storage tier 1 (NVMe):
  Total size: 3.8 GB
  Free: 3.7 GB, min:3.7 GB, max:3.7 GB, mean:3.7 GB
Rebuild idle, 0 objs, 0 recs
[root@e65332746210 daos]# dmg pool list --verbose
Label UUID                                 State SvcReps SCM Size SCM Used SCM Imbalance NVME Size NVME Used NVME Imbalance Disabled UpgradeNeeded? 
----- ----                                 ----- ------- -------- -------- ------------- --------- --------- -------------- -------- -------------- 
sxb   9b6324da-f57a-4cd7-9586-989e9259f60e Ready 0       240 MB   206 kB   0%            3.8 GB    42 MB     0%             0/1      None           

[root@e65332746210 daos]# daos container query sxb sxb --verbose
  Container UUID              : 0b22f857-de4d-407d-a4a3-8ee620c6fa7d                        
  Container Label             : sxb                                                         
  Container Type              : POSIX                                                       
  Pool UUID                   : 9b6324da-f57a-4cd7-9586-989e9259f60e                        
  Container redundancy factor : 0                                                           
  Number of open handles      : 1                                                           
  Latest open time            : 0x10dd92ddb5880000 (2023-05-30 02:45:59.711932416 +0000 UTC)
  Latest close/modify time    : 0x10dd92dde3b00000 (2023-05-30 02:45:59.760330752 +0000 UTC)
  Number of snapshots         : 0                                                           
  Object Class                : UNKNOWN                                                     
  Dir Object Class            : UNKNOWN                                                     
  File Object Class           : UNKNOWN                                                     
  Chunk Size                  : 1.0 MiB                                                     


获取属性:
[root@e65332746210 sxb]# daos cont get-prop sxb sxb
Properties for container sxb
Name                                             Value                               
----                                             -----                               
Highest Allocated OID (alloc_oid)                1                                   
Checksum (cksum)                                 off                                 
Checksum Chunk Size (cksum_size)                 32 KiB                              
Compression (compression)                        off                                 
Deduplication (dedup)                            off                                 
Dedupe Threshold (dedup_threshold)               4.0 KiB                             
EC Cell Size (ec_cell_sz)                        64 KiB                              
Performance domain affinity level of EC (ec_pda) 1                                   
Encryption (encryption)                          off                                 
Global Version (global_version)                  2                                   
Group (group)                                    root@                               
Label (label)                                    sxb                                 
Layout Type (layout_type)                        POSIX (1)                           
Layout Version (layout_version)                  1                                   
Max Snapshot (max_snapshot)                      0                                   
Object Version (obj_version)                     1                                   
Owner (owner)                                    root@                               
Redundancy Factor (rd_fac)                       rd_fac0                             
Redundancy Level (rd_lvl)                        node (2)                            
Performance domain affinity level of RP (rp_pda) 3                                   
Server Checksumming (srv_cksum)                  off                                 
Health (status)                                  HEALTHY                             
Access Control List (acl)                        A::OWNER@:rwdtTaAo, A:G:GROUP@:rwtT 


调试:
dlv exec /opt/daos/bin/daos -- cont create --oclass=RP_3GX --properties=rf:1 --type POSIX --pool sxb --label sxb
gdb /opt/daos/bin/daos
set args cont create --oclass=RP_3GX --properties=rf:1 --type POSIX --pool sxb --label sxb1

池
gdb /opt/daos/bin/dmg
set args pool create sxb -z 4g
b xxx 
r


查容器:
daos cont query sxb sxb


挂载/卸载
mkdir -p /tmp/sxb
dfuse --mountpoint=/tmp/sxb --pool=sxb --cont=sxb   # mount.fuse3 dfuse /scratch_fs/daos_dfuse_samir -o pool=samirrav_pool,container=samirrav_cont
echo 'dfuse /scratch_fs/root_dfuse fuse3 pool=admin_pool,container=admin_cont,auto,x-systemd.requires=daos_agent.service    0 0' >> /etc/fstab
cd /tmp/sxb

umount /tmp/sxb

查看系统调用
strace -o xxx.log -fff exec -f config_file



参考: DaosObjectType.java
oclass: 对象类型(object class), 具有明确布局的副本对象, 第一个数字是副本数，G后面的数字代表冗余组的数量
2G1 : 2个副本, 分布在冗余组1
8GX : 8 个副本，它分布在池中的所有目标上


kill engine:
ps aux|grep '/opt/daos/bin/daos_engine'|grep -v grep|awk '{print$2}'|xargs kill -9

tail -f /tmp/daos_*.log

pkill daos_agent daos_server
daos_agent
daos_server start

pkill daos_agent daos_server;daos_agent & daos_server start

dmg server set-logmasks ERR,mgmt=debug,cart=debug,hg=debug,external=debug,object=debug

dmg server set-logmasks debug

umount /mnt/sxb

mkdir /mnt/sxb
dfuse --m=/mnt/sxb --pool=sxb --cont=sxb
cd /mnt/sxb

for i in {0..5};do
  echo "$i, `date`"
  dd if=/dev/zero of=$i bs=1M count=100 oflag=direct
  sleep 3
done

docker
pc(client) -> ssh -> ubuntu(code) -> map_volume -> docker
cp -r /home/daos/pre/build .


DAOS Tour test


code:




FI_ORDER_SAS: send after send

struct ofi_prov		*next: 提供者是一个单向链表



scons build:
require -> comp_def.configure() -> comp_def.build -> if has_changes or self.has_missing_targets

rebuild mercury, site_scons/prereq_tools/base.py, 
def _has_changes(self)
  if self.name == mercury:...
build cache
rm -f .sconsign.dblite

find . -name "mercury_config.h"
readlink -f ./mercury.build/src/mercury_config.h

头文件搜索路径:
export C_INCLUDE_PATH=$C_INCLUDE_PATH:/home/xb/project/stor/daos/origin/docker/daos/build/external/debug/mercury.build/src/na:/home/xb/project/stor/daos/origin/docker/daos/build/external/debug/mercury.build/src:/home/xb/project/stor/daos/origin/docker/daos/build/external/debug/mercury/src:/home/xb/project/stor/daos/origin/docker/daos/build/external/debug/mercury/src/na:/home/xb/project/stor/daos/origin/docker/daos/build/external/debug/mercury/src/util:/home/xb/project/stor/daos/origin/docker/daos/build/external/debug/mercury/src/proc_extra

echo '/lib64/' >> /etc/ld.so.conf
ldconfig
ldconfig -p|grep mercury
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/lib64/:/opt/daos/prereq/debug/mercury/lib/:/opt/daos/prereq/debug/mercury/include/
cd /home/xb/project/stor/daos/origin/docker/daos/build/external/debug/mercury/mercury/build/05_bulk
make



git commit --amend
git format-patch -1

reset single file
git checkout HEAD -- fi_domain.h


性能调优: https://docs.daos.io/v2.0/admin/performance_tuning/
As an example, an engine with targets: 16 and nr_xs_helpers: 4 would use the following tag distributions:
tag 0: metadata service
tag 1: monitoring service
tag 2-17: targets 0 to 15 (16 targets total)
tag 18-21: helper service

self_test:
export D_LOG_MASK=debug
export DD_SUBSYS=all
export DD_MASK=all

self_test -u --group-name daos_server --endpoint 0:2 --message-size '(b1048578 b1048578)' --max-inflight-rpcs 16 --repetitions 100
self_test -u --group-name daos_server --endpoint 0:2 --message-size '(0 0)' --max-inflight-rpcs 16 --repetitions 1000

主流程
main(int argc, char *argv[]) -> d_log_init -> 解析和校验参数 -> run_self_test -> cleanup

run_self_test -> 定义 latencies 内存结构 -> self_test_init 初始化cart -> crt_group_rank -> crt_group_lookup -> qsort 排序 -> d_iov_set -> crt_bulk_create -> test_msg_size -> cleanup

self_test_init -> crtu_test_init -> dc_agent_init 获取socket_path -> crtu_dc_mgmt_net_cfg_setenv 设置环境变量 -> crt_init 初始化传输层(crt_init_opt) crt_self_test_init 全局锁 -> crt_context_create -> crt_group_view_create -> crtu_dc_mgmt_net_cfg_rank_add -> progress_fn 推进rpc crt_progress -> crt_group_ranks_get 查找某个组的ranks -> crt_group_psr_set 设置服务主rank -> crtu_wait_for_ranks -> crt_rank_self_set 设置自己的rank


crt_init_opt -> d_log_init -> crt_setup_log_fac -> data_init 初始化全局配置/流控 -> prov_data_init 设置属性 -> crt_hg_init HG/NA日志初始化 -> crt_grp_init -> crt_plugin_init 回调 -> crt_self_test_init -> crt_opc_map_create -> crt_internal_rpc_register -> crt_proto_register_internal(&cpf) -> crt_proto_register -> crt_opc_reg_internal -> crt_opc_reg 设置属性 回调 -> opc_info->coi_crf = crf 操作码信息_crt请求格式, 控制器

crt_opc_map_create -> crt_opc_map_L2_create

crt_grp_init -> crt_primary_grp_init -> crt_grp_priv_create -> grp_priv_init_membs -> crt_grp_lc_create


cg_credit_ep_ctx: 流控, 每个目标EP CTX的inflight RPC 的积分限制

crt_context_create:
crt_context_provider_create -> 网络抽象初始化 -> ofi建连接(走内核,成本高) ->  内存池, 地址池(priv->addr_pool), 地址hash表(domain->addr_ht) -> 


crt_context_create -> crt_context_provider_create -> crt_context_init -> crt_hg_ctx_init -> crt_hg_get_addr -> d_list_add_tail 插入链表尾部 -> crt_provider_inc_cur_ctx_num 上下文索引号自增 -> 启动传感器sensors? -> crt_provider_name_get 获取提供者名 -> d_tm_add_metric 添加指标 -> crt_swim_init 初始化swim? -> 慢网(sockets/tcp_rxm)


crt_context_init -> d_binheap_create_inplace crt_timeout_bh_ops cc_bh_timeout -> d_hash_table_create_inplace epi_table_ops cc_epi_table


crt_hg_ctx_init -> crt_hg_class_init -> HG_Context_create -> HG_Context_set_data -> crt_hg_pool_init

crt_hg_class_init -> crt_get_info_string -> HG_Init_opt -> crt_hg_get_addr -> crt_hg_reg_rpcid


HG_Init_opt -> HG_Core_init_opt -> HG_Core_set_more_data_callback

HG_Core_init_opt -> hg_core_init -> NA_Initialize_opt -> NA_Msg_get_max_tag  na_ofi_msg_get_max_tag -> hg_hash_table_new

NA_Initialize_opt -> na_info_parse 解析和填充主机信息 -> check_protocol 先检查协议 na_ofi_check_protocol -> initialize na_ofi_initialize

na_ofi_initialize -> na_ofi_prov_name_to_type -> na_ofi_check_interface -> HG_QUEUE_INIT(&priv->addr_pool) 初始化地址池 -> na_ofi_domain_open -> hg_mem_pool_create -> 


HG_Context_create -> 


crt_group_view_create 创建本地组视图(仅客户端) -> crt_grp_priv_create 初始化链表 -> grp_priv_init_membs -> crt_grp_lc_create uri和地址查找缓存lookup_cache -> d_list_add_tail 将gp_link插入全局链表

crtu_dc_mgmt_net_cfg_rank_add 管理网络配置/添加rank -> dc_get_attach_info 获取附着信息(包含所有rank的uri) -> crt_group_primary_rank_add 将uri插入crt上下文的查找缓存表中, 针对0号tag, 将rank加入组成员列表中

crt_progress -> crt_hg_progress poll cq -> crt_context_timeout_check 超时检查 -> crt_exec_progress_cb


crtu_wait_for_ranks -> sem_init -> crt_req_create -> crt_req_set_timeout -> crt_req_send -> crtu_sync_timedwait
crt_req_create -> crt_req_create_internal -> crt_rpc_priv_alloc 分配rpc请求私有数据 -> crt_rpc_priv_init 设置初始状态:rpc_priv->crp_state = RPC_STATE_INITED -> crt_opc_lookup 查找操作码 


RPC_STATE_INITED -> 

查找目标地址:
crt_req_send -> crt_req_send_internal -> crt_req_ep_lc_lookup -> crp_hg_addr (na_addr) -> 地址作为 HG_Create 的参数(目的地址) -> crt_req_send_immediately -> crt_hg_req_create RPC_STATE_REQ_SENT 创建请求,设置状态为发送 -> crt_hg_req_send -> HG_Forward -> HG_Core_forward -> forward(hg_core_handle) -> hg_core_forward_na -> NA_Msg_send_unexpected -> na_ofi_msg_send_unexpected -> na_ofi_msg_send -> fi_tsend

目标地址: crp_tgt_uri
crt_req_send_internal -> crt_req_ep_lc_lookup -> crt_req_fill_tgt_uri -> crp_tgt_uri

crt_issue_uri_lookup


crt_hg_req_create -> 控制器复用:HG_Reset -> 不复用:HG_Create -> 



crt_hg_req_send -> HG_Forward(rpc_priv->crp_hg_hdl, crt_hg_req_send_cb 由HG转发(同时设置完成回调) -> 






复用控制器
rpc_priv->crp_hdl_reuse

coi_no_reply:1 /* one-way */ 单程(无需响应,默认)


test_msg_size -> crt_req_create -> 

crt_req_create(crt_ctx, endpt, CRT_OPC_SELF_TEST_START
CRT_OPC_SELF_TEST_STATUS_REQ -> crt_bulk_transfer -> crt_hg_bulk_transfer -> HG_Bulk_transfer_id, HG_Bulk_transfer -> hg_bulk_transfer -> hg_bulk_transfer_na -> hg_bulk_na_put -> NA_Put -> put -> na_ofi.c -> na_ofi_put -> na_ofi_rma fi_writemsg -> writemsg -> vrb_msg_ep_rma_writemsg -> wr.opcode = IBV_WR_RDMA_WRITE -> vrb_send_iov -> vrb_post_send -> ibv_post_send



crt_bulk_create -> crt_hg_bulk_create -> HG_Bulk_create -> hg_bulk_create -> hg_bulk_create_na_mem_descs -> hg_bulk_register -> NA_Mem_handle_create mem_handle_create -> NA_Mem_register na_ofi_mem_register -> fi_mr_regv -> fi_mr_key


crt scons 编译:
gurt/SConscript
cart/SConscript
cart_ctl
export D_LOG_MASK=DEBUG
export DD_MASK=all
export DD_SUBSYS=all
cart_ctl enable_fi -g daos_server -u
Build cart_ctl -> cart_ctl.c -> main -> parse_args -> crtu_test_init -> dc_agent_init -> ctl_init -> d_log_fini

ctl_init -> crtu_cli_start_basic -> sem_init -> crtu_wait_for_ranks -> ctl_register_ctl -> crt_req_create -> crt_req_send ctl_cli_cb -> crtu_sem_timedwait


crtu_cli_start_basic -> crtu_dc_mgmt_net_cfg_setenv -> ctl_init -> crt_context_create -> crtu_progress_fn -> crt_group_view_create -> crtu_dc_mgmt_net_cfg_rank_add -> crt_group_size -> crt_group_ranks_get -> crt_group_psr_set

ctl_init -> crt_init_opt



crtu_test_init -> 

swim:
self_id:18446744073709551615, swim_prot_period_len:1000,swim_suspect_timeout:8000,swim_ping_timeout:900,sc_next_tick_time:94491384(10/23-15:32:10.61)
daos_server -> engine -> main(int argc, char **argv) -> parse(argc, argv) 解析参数 -> server_init -> d_tm_record_timestamp -> dss_srv_init -> dss_xstreams_init -> dss_start_xs_id -> dss_start_one_xstream -> ABT_thread_create -> dss_srv_handler -> crt_context_create -> crt_context_provider_create -> crt_swim_init -> swim_init

阻止所有除了故障之外可能的信号
engine -> server_fini

server_init -> daos_debug_init -> dss_engine_metrics_init -> drpc_init -> register_dbtree_classes -> dss_topo_init -> abt_init -> dss_module_init interface初始化 -> crt_init_opt 网络初始化-> dss_module_init_all -> vos,rdb,rsvc,security,mgmt,dtx,pool,cont,obj,rebuild 模块初始化 -> dss_srv_init 服务初始化


crt_context_provider_create -> crt_provider_inc_cur_ctx_num 创建crt上下文后,将index自增1 -> cpg_ctx_num++ -> crt_context_register_rpc_task 注册公用rpc控制器 -> crt_context_idx  ctx->cc_idx = cur_ctx_num ->

send_request -> crt_swim_send_request -> crt_ctx = crt_context_lookup(ctx_idx) -> ctx->cc_idx == ctx_idx -> crt_req_create(crt_ctx, &ep, opc, &rpc) -> crt_req_send(rpc, crt_swim_cli_cb, ctx)


crt_swim_init -> swim_init -> crt_swim_rank_add -> crt_proto_register -> crt_register_progress_cb(crt_swim_progress_cb, crt_ctx_idx, NULL) 设置回调 -> swim_progress
swim_init -> 设置上下文属性

swim_prot_period_len: ping周期(1000ms)
swim_suspect_timeout: 质疑超时(8000ms)

crt_proto_register -> crt_proto_register_common -> crt_proto_reg_L1 -> crt_proto_reg_L2 -> crt_proto_reg_L3

if (send_updates) -> swim_updates_send -> 


engine -> server_init -> crt_init_opt -> crt_grp_init -> crt_primary_grp_init -> crt_grp_priv_create -> grp_priv_init_membs -> crt_grp_lc_create


server_init -> dss_module_init_all -> dss_module_init_one -> sm_init() -> ds_mgmt_init -> ds_mgmt_system_module_init 

ubip_server -> cmd.start = server.Start -> func Start 启动服务 -> registerEvents 注册事件 -> OnLeadershipGained 获得领导力 -> startJoinLoop -> func (svc *mgmtSvc) joinLoop -> func (svc *mgmtSvc) doGroupUpdate -> MethodGroupUpdate -> DRPC_METHOD_MGMT_GROUP_UPDATE -> ds_mgmt_drpc_group_update (in MS leader 主服务器) -> ds_mgmt_group_update_handler -> ds_rsvc_request_map_dist 广播集群map -> ABT_cond_broadcast -> sc_map_dist -> mgmt_svc_map_dist_cb -> map_update_bcast map更新广播 -> crt_corpc_req_create 创建rpc集合请求 MGMT_TGT_MAP_UPDATE 目标map更新 -> crt_grp_priv_get_primary_rank -> crt_corpc_info_init  -> d_rank_list_dup_sort_uniq -> dss_rpc_send -> crt_reply_get

dss_rpc_send -> crt_req_send(rpc, rpc_cb, &eventual) -> 


ds_mgmt_drpc_group_update 更新组信息 map_version -> ds_mgmt_group_update_handler -> ds_mgmt_group_update 组更新  REPLACE -> init_map_distd -> map_distd ->  d_hash_rec_find(& -> crt_group_primary_modify 编辑主要组(原子增/删/替换) -> crt_group_mod_get 获取添加和删除列表 -> grp_add_to_membs_list 添加成员 / crt_group_rank_remove_internal 移除rank -> crt_swim_rank_add -> grp_lc_uri_insert_internal_locked 插入uri查找缓存 ->



请求异步集群位图分发。 这最终会触发 ds_rsvc_class.sc_map_dist，它必须由 rsvc 类实现。

MethodSetRank -> ds_mgmt_drpc_set_rank -> crt_rank_self_set -> grp_add_to_membs_list -> crt_provider_get_ctx_list -> crt_hg_get_addr -> crt_grp_lc_uri_insert


grp_add_to_membs_list -> grp_get_free_index -> crt_swim_rank_add -> grp_regen_linear_list


广播一个条件。 ABT_cond_broadcast() 向所有在条件变量 cond 上阻塞的服务员发出信号。 调用者不需要持有与 cond 关联的互斥锁。 如果当前没有服务员在 cond 上阻塞，则此例程无效。


集体传播的树形拓扑
k-nomial tree k项树是一种在软件中实现集体通信操作的有效方法。 与 n 叉树不同，k 项树中的子节点数量随着任务深度的增加而减少（即，没有任务的子节点比根节点多）。 优点是更早开始通信的任务执行更多的工作，从而减少了集体操作的总延迟。 相比之下，在 n-ary 树中，较早开始通信的任务会较早完成，但会增加总延迟。 概念通过 KNOMIAL_PARENT、KNOMIAL_CHILDREN 和 KNOMIAL_CHILD 函数支持 k-nomial 树，如下所述。

该图是随着时间向下流动的结构。 也就是说，对于在 2 项树上表示的多播操作，任务 0 在第一个时间步向任务 1 发送消息。 然后，任务 0 发送到任务 2，而任务 1 发送到任务 3。最后一步，任务 0 发送到任务 4，任务 1 发送到任务 5，任务 2 发送到任务 6，任务 3 发送到任务 7—— 全部同时进行。 假设计算中总共有八个任务，以下表达式也成立：



swim_member_new_remote -> 

swim状态机:
SCS_TIMEDOUT -> SCS_SELECT (第一次未获取到目标) -> 获取到有效目标 -> SCS_BEGIN


swim_member_update_suspected -> 

sed -i 's/PermitRootLogin prohibit-password/PermitRootLogin yes/' /etc/ssh/sshd_config
# sed 's@session\s*required\s*pam_loginuid.so@session optional pam_loginuid.so@g' -i /etc/pam.d/sshd

CMD ["/usr/sbin/sshd", "-D"]
ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key
/usr/sbin/sshd


for ip in 172.17.0.3 172.17.0.4;do rsync -rucalpzv /opt/daos root@$ip:/opt/;done

run_all "sed -i s/DD_SUBSYS=all/DD_SUBSYS=swim,cart,mgmt/g /opt/daos/etc/daos_server.yml"
run_all "sed -i s/#- FI_LOG_LEVEL=debug/- FI_LOG_LEVEL=debug/g /opt/daos/etc/daos_server.yml"

run_all "sed -i /.*FI_LOG_LEVEL=.*/d /opt/daos/etc/daos_server.yml"
run_all "sed -i '/env_vars:/a \ \ - FI_LOG_LEVEL=debug' /opt/daos/etc/daos_server.yml"


Hybrid Logical Clock (HLC): hlc 混合逻辑时钟, 

ips2='172.17.0.2 172.17.0.3 172.17.0.4'
function run_all(){
	local command=$*
	if [[ $* == "" ]]; then
	    echo "$1 cmd"
	else
		for ip in $ips2; do
			echo -e  "\n\033[32m`date +'%Y/%m/%d %H:%M:%S'` $ip $*\033[0m"
                        if [[ $ip == '172.17.0.2' ]];then
                            ${command}
			else
			    ssh $ip "${command}"
                        fi
		done
	fi
}

crt_progress(dmi->dmi_ctx, dx->dx_timeout) 0ms -> crt_exec_progress_cb -> cb_func = cbs_prog[i].cpcp_func -> swim_progress

git format-patch -1 24ea9400e30d67458bb2b970b52b81d4fdfe8f59
git format-patch -1
#mac: cd /Users/xb/OneDrive/storage/daos && scp root@xb-ubuntu:/root/github/storage/daos/origin/docker/daos/0001-build-docker-image-release-v2.0.1.patch .



egrep -v 'grp_lc_uri_insert_internal_locked|prealloc_requests|grp_li_uri_set' daos_engine.0.log |less



查找时排除
build,cache,tests,


mochi rdma mercury bulk:
https://mochi.readthedocs.io/en/latest/mercury/05_bulk.html
客户端:
HG_Init -> HG_Context_create -> MERCURY_REGISTER -> HG_Addr_lookup -> lookup_callback  HG_Trigger HG_Progress -> HG_Create -> HG_Bulk_create -> HG_Forward -> save_completed 转发完成后回调 -> HG_Get_output -> assert

服务端:
build/external/debug/mercury/mochi/05_bulk/server.c
HG_Init -> ... -> MERCURY_REGISTER save -> HG_Get_input -> HG_Bulk_create -> HG_Bulk_transfer -> fwrite -> HG_Respond

dump
获取缓存uri:
cart_ctl get_uri_cache --group-name daos_server -u

查看上下文:
cart_ctl list_ctx --group-name daos_server -u --rank 1

cart_ctl get_pid --group-name daos_server -u --rank 0-2


操作码: CRT_CTL_RPCS_LIST -> cpf.cpf_name  = "ctl" -> 
crt_proto_rpc_format

opc_info->coi_rpc_cb 收到rpc请求时回调 hg_proc_info->rpc_cb = rpc_cb -> crt_handle_rpc  crt_rpc_common_hdlr -> 

crt_hg_reg -> crt_rpc_common_hdlr

调度:
req_kickoff_internal -> 




sched_run -> sched_start_cycle -> process_all -> d_hash_table_traverse(info->si_pool_hash, process_pool_cb, dx) 遍历一个哈希表，对每一项调用遍历回调函数。 一旦回调返回非零就中断 -> sri_req_cnt -> 
crt_context_register_rpc_task -> dss_rpc_hdlr rpc控制器 -> sched_req_enqueue 请求入队 -> sri_req_cnt



daos_obj_update


对象更新
obj_tgt_update -> ds_obj_remote_update -> DAOS_OBJ_RPC_TGT_UPDATE -> crt_req_send(req, shard_update_req_cb, remote_arg) 发送RPC -> 



engine -> for (;;) 一直循环 -> crt_progress -> crt_hg_progress -> HG_Progress 推进RPC -> HG_Trigger 触发回调


hg_atomic_queue_push completion_queue -> hg_thread_cond_signal

HG_Trigger -> HG_Core_trigger -> hg_core_trigger -> hg_completion_entry = hg_atomic_queue_pop_mc(context->completion_queue) 从完成队列中取出一个条目 -> hg_core_trigger_entry 根据条目内容触发 -> hg_cb(&hg_core_cb_info) 执行用户回调(最终执行crt_req_send传入的完成回调)


coi_no_reply -> CRT_HG_ONEWAY_RPCID: 单程rpc(禁用响应) 

发送请求
crt_req_send(req, shard_update_req_cb, remote_arg) 将用户回调设置为完成回调:crp_complete_cb, HG_Forward 在 crt_hg_req_send_cb 中执行完成回调:crp_complete_cb

查询:
查leader: dmg sys leader-query

打开err日志:
dmg server set-logmasks err


vos_tests: gdb /opt/daos/bin/vos_tests
set args -p 

启动容器:
daos_start_all

停止所有服务:
daos_stop_all


客户端:
文件系统操作表: dfuse_pool_ops

查看系统调用:
strace -fff test/write_file /tmp/sxb/test1


gdb调试fuse:
gdb attach `ps aux|grep dfuse|grep -v grep|awk '{print$2}'`

kill dfuse
kill -9 `ps aux|grep dfuse|grep -v grep|awk '{print$2}'`

gdb条件断点:
(gdb) b ds_obj_rw_handler if opc==DAOS_OBJ_RPC_FETCH







vos初始化
vos_db_init



bug:
停服务,引用计数不对
HG_Context_destroy
  hg_core_context_destroy 1 remaining


单元测试, daos_test, 
run_test.sh
  eq_test 事件队列测试

拦截库IL, 
ioil_do_writex
一个名为 libioil 的拦截库可用于 DFuse。 该库与 DFuse 结合使用，允许拦截 POSIX I/O 调用并通过 libdaos 直接从应用程序上下文发出 I/O 操作，而无需任何应用程序更改。 这为 I/O 数据提供了内核旁路，从而提高了性能
unified namespace integration: 集成统一命名空间

客户端
dfuse


git raft子项目: git submodule update && git submodule update

编译spdk:
cd build/external/debug/spdk
./configure --help
yum install ncurses-devel ncurses
./configure --prefix="/opt/daos/prereq/debug/spdk" --disable-tests --disable-unit-tests --disable-apps --without-vhost --without-crypto --without-pmdk --without-rbd --with-rdma --without-iscsi-initiator --without-isal --without-vtune --with-shared

../share/daos/control/setup_spdk.sh
/opt/daos/prereq/debug/spdk/share/spdk/scripts/setup.sh

Running commands in /home/xb/project/stor/daos/origin/docker/daos
command:cp -r cache/spdk /home/xb/project/stor/daos/origin/docker/daos/build/external/debug/spdk
Running commands in /home/xb/project/stor/daos/origin/docker/daos/build/external/debug/spdk
command:git checkout v21.07




qa:
spdk缺elftools
centos7
pip3 install pyelftools

spdk:
Install CentOS SCLo RH repository:
yum install centos-release-scl-rh
Install CUnit rpm package:
# yum install CUnit





调试手段
gdb step
1. add sleep 10s in init, src/engine/init.c:1093
2. gdb attach, break, continue
3. step


dlv调试go:
dlv exec /opt/daos/bin/daos_server -- start

证书:
container: mkdir -p /etc/daos/certs/
ubuntu: docker cp /root/github/storage/daos/origin/docker/daos/utils/config/examples/certs daos:/etc/daos/certs/

分配rpc:
crt_rpc_priv_alloc
crt_rpc_inout_buff_init

代码规范: 注释
/**
 * Set the timeout value for an RPC request.
 *
 * \param[in] timeout_sec      timeout value in seconds. value of zero will be
 *                             treated as invalid parameter.
 *
 * \return                     DER_SUCCESS on success, negative value if error
 */
int
crt_req_set_timeout(crt_rpc_t *req, uint32_t timeout_sec);


openssl/kdf.h, yum install -y openssl11-devel

安装依赖
source "$scriptsdir/pkgdep/$id.sh" -> centos.sh

code_flow
dfs_mount 挂载daos文件系统
spdk -> dfs_mount(ch->pool, ch->cont, O_RDWR, &ch->dfs)
	prop = daos_prop_alloc(0)
	daos_cont_query(coh, NULL, prop, NULL)
	entry = daos_prop_entry_get(prop, DAOS_PROP_CO_LAYOUT_TYPE)
	daos_acl_principal_to_uid(entry->dpe_str, &dfs->uid)
	DAOS_PROP_CO_ROOTS superblock or root
	open_sb(coh, false, dfs->super_oid, &dfs->attr, &dfs->super_oh)
	open_dir(dfs, NULL, amode | S_IFDIR, 0, &root_dir, 1, &dfs->root)
	if (amode == O_RDWR)
		daos_cont_alloc_oids(coh, 1, &dfs->oid.lo, NULL) 超级块OID=0, 根OID=1
	
打开文件系统
dfs_open(ch->dfs, NULL, daos->disk.name, mode, fd_oflag, daos->oclass, 0, NULL, &ch->obj)
	dfs_open_stat


dmg -i storage format

build_client(only):
scons-3 BUILD_TYPE=debug TARGET_TYPE=debug client install --build-deps=yes


engine start -> engine/init.c -> main

spdk
spdk_blob_io_write

拦截库:libioil -> IOIL_SRC = ['int_posix.c', 'int_read.c', 'int_write.c'] -> src/client/dfuse/il/int_write.c -> ioil_do_pwritev -> 自动去掉前缀 dfuse_ -> __attribute__((weak, alias("dfuse_" #name)))
writev -> dfuse_writev -> pwritev_rpc -> bytes_written = ioil_do_pwritev
pwritev -> dfuse_pwritev
d_iov_set
dfs_write



为挂载点、池、容器添加对位置参数的支持, 如果要通过 fstab 挂载 dfuse，则只给出一个选项，即挂载点，因此将其放在第一位，但如果给定，也接受池和容器。 检修 dfuse_pool_connect 函数, 这允许通过标准的 mount 命令和 fstab 通过如下一行来安装dfuse：dfuse /mnt/dfuse fuse3 默认值，用户 0 0
dfuse -> src/client/dfuse/dfuse_main.c -> main






src/client/dfuse/ops/write.c -> dfuse_cb_write




vos_blob_format_cb
  bio_write_blob_hdr
    bio_write
      bio_rw
        bio_rwv
          bio_iod_post 提交io描述
            dma_rw
              nvme_rw
                spdk_blob_io_write rw_completion
                  blob_request_submit_op
                    blob_request_submit_op_single
                      bs_batch_write_dev
                        blob_bdev->bs_dev.write
                        bdev_blob_write
                          spdk_bdev_write_blocks


rw_completion
  spdk_thread_send_msg


客户端mount:
ufuse -m /mnt/sxb --pool sxb --cont sxb
ufuse_main.c -> main dfuse_main.c
  ubip_debug_init daos_debug_init
    d_log_init_adv 高级日志初始化, 客户端日志文件
      log_file = getenv(D_LOG_FILE_ENV) export D_LOG_FILE=/tmp/daos_client.log
      debug_prio_err_load_env
      d_log_open
        freopen(mst.log_file 重新关联标准输出或错误输出
        setlinebuf(stderr) 设置错误输出为行缓冲
    d_log_sync_mask
  daos_init
    daos_eq_lib_init 事件队列
      crt_init_opt
  dfuse_fs_init
    d_hash_table_create_inplace dpi_pool_table 打开的池表， 创建hash表 大小=power2(n次方)， 操作方法
    dpi_iet open inodes
    daos_eq_create 一个事件队列关联一个网络上下文， 跟踪池的多个事件
      daos_eq_alloc
      crt_context_create(&eqx->eqx_ctx)
        crt_contpext_provider_create
          crt_context_init
      daos_eq_insert(eqx)
      daos_eq_handle(eqx, eqh)
      tse_sched_init(&eqx->eqx_sched, NULL, eqx->eqx_ctx)
    sem_init
  duns_resolve_path
  dfuse_pool_connect
  dfuse_cont_open
  dfuse_start dfuse_fs_start 启动文件系统
    d_hash_rec_insert(&fs_handle->dpi_iet 将根插入hash表, 在 dfuse_reply_entry 中也会插入: d_hash_rec_find_insert(&fs_handle->dpi_iet
    d_slab_init
    d_slab_register
    dfuse_progress_thread pthread_create(&fs_handle->dpi_thread, NULL, dfuse_progress_thread, fs_handle) 异步进度线程，该线程在启动时使用事件队列启动，并阻塞在信号量上，直到创建异步事件，此时线程唤醒并在 daos_eq_poll() 中忙于轮询直到完成
      sem_wait
      daos_eq_poll  从 EQ 中检索完成事件
        daos_eq_lookup 查找私有事件队列
          daos_hhash_link_lookup
        crt_progress_cond(epa.eqx->eqx_ctx, timeout, eq_progress_cb, &epa)
          eq_progress_cb
        dfuse_launch_fuse(fs_handle, &args) 创建fuse文件系统
          fuse_session_new(args, &dfuse_ops, sizeof(dfuse_ops), fs_handle)
          fuse_session_mount
          dfuse_send_to_fg
          dfuse_loop
  dfuse_fs_fini


dfuse_progress_thread
  rc = sem_wait(&fs_handle->dpi_sem) 等dpi_sem信号
  daos_eq_poll
  daos_event_fini 完成一个事件。 如果事件已被传递到任何 DAOS API，则它只能在从 EQ 中轮询出来时才能完成，即使通过调用 daos_event_abort() 中止也是如此。 如果事件是用父事件初始化的，那么该事件将从父事件的子列表中删除。 如果ev本身是一个父事件，那么这个函数会finalize所有的子事件和ev。
  ev->de_complete_cb(ev) -> dfuse_cb_write_complete 写完成回调

struct fuse_lowlevel_ops dfuse_ops dfuse低层操作对象
  .create		= df_ll_create
	.open		= dfuse_cb_open,
	.release	= dfuse_cb_release,
	.write_buf	= dfuse_cb_write,
	.read		= dfuse_cb_read,
	.readlink	= dfuse_cb_readlink,
	.ioctl		= dfuse_cb_ioctl,

struct fuse_file_info libfuse


客户端写数据：write.c
write -> dfuse_cb_write 回调写 src/client/dfuse/fuse3
  fuse_req_userdata
  fuse_req_ctx
  fuse_buf_size(bufv)
  ibuf = FUSE_BUFVEC_INIT(len) 分配本地缓冲区
  DFUSE_TRA_DEBUG 调试
  fuse_buf_copy(&ibuf, bufv, 0)
  dfuse_cache_evict
  d_slab_acquire 以高效的方式分配数据
  fuse_buf_copy libfuse
  daos_event_init 线程事件初始化
    evx->evx_status	= DAOS_EVS_READY
    D_INIT_LIST_HEAD(&evx->evx_child) 初始化链表
    daos_eq_putref 从事件队列继承传输上下文
  ev->de_complete_cb = dfuse_cb_write_complete 设置回调
  d_iov_set(&ev->de_iov, ibuf.buf[0].mem, len)  # 设置io向量， 将第二参数的地址和长度赋值给第一个参数
  ev->de_sgl.sg_iovs = &ev->de_iov   sgl分散聚集列表
  readahead ie_truncated 预读和截断
  dfs_write (文件系统， 对象，sgl列表，文件(对象)偏移，事件) 将数据写到文件对象
    事件为空
      daos_event_launch
      daos_event_complete
    daos_event_errno_rc(ev) 将错误码转正
      daos_ev2evx(ev)
    daos_array_write 写数组对象: daos_array_write(obj->oh, DAOS_TX_NONE, &iod, sgl, ev)
      dc_task_create(dc_array_write, NULL, ev, &task) 创建任务
      dc_task_schedule(task, true)  task与args做转换: dc_task_get_args 调度任务
    return daos_der2errno(rc)
  sem_post(&fs_handle->dpi_sem)   解锁信号量(+1,如果大于0,其他线程将被唤醒执行),唤醒线程（线程同步）: dfuse_progress_thread sem_wait(&fs_handle->dpi_sem)


dc_array_write
  daos_task_get_args task和args可互转
  dc_array_io opc = DAOS_OPC_ARRAY_WRITE 操作码是写数组  读:DAOS_OPC_ARRAY_READ
    array_hdl2ptr
    io_extent_same
    D_INIT_LIST_HEAD(&io_task_list)
    daos_task_create(DAOS_OPC_ARRAY_GET_SIZE 短读任务 DAOS_OPC_ARRAY_READ
    while (u < rg_iod->arr_nr) 遍历每个范围，但同时组合属于同一 dkey 的连续范围。 如果用户给出的范围不增加偏移量，则它们可能不会合并，除非分隔范围也属于同一个 dkey
      compute_dkey 计算分布式key 在给定此范围的数组索引的情况下计算 dkey。 还计算从我们开始的索引开始，dkey 可以保存的记录数写作。 相对于 dkey 的记录索引
      struct io_params *prev, *current 如果有多个dkey io, 则通过链表连接起来
      num_ios++
      d_iov_set(dkey, &params->dkey_val, sizeof(uint64_t));
      d_iov_set(&iod->iod_name, &params->akey_val, 1);
      compute_dkey 再次计算dkey
      create_sgl 创建分散聚集列表
      daos_task_create(DAOS_OPC_OBJ_FETCH 读: DAOS_OPC_ARRAY_READ 按索引号 -> dc_obj_fetch_task
      daos_task_create(DAOS_OPC_OBJ_UPDATE 写 或 DAOS_OPC_ARRAY_PUNCH truncate dc_funcs[opc].task_func 客户端方法数组
      daos_task_get_args
      tse_task_register_deps 注册在计划任务之前需要完成的依赖任务。 依赖任务无法进行, 如果一个任务依赖于其他任务，只有依赖的任务完成了，才可以将任务添加到调度器列表中
      tse_task_list_add(io_task, &io_task_list)  d_list_add_tail(&dtp->dtp_task_list, head); 添加任务到链表
    tse_task_register_comp_cb(task, free_io_params_cb, &head, sizeof(head))  为任务注册完成回调
    if (op_type == DAOS_OPC_ARRAY_READ && array->byte_array) 短读
      tse_task_register_deps(task, 1, &stask) 注册依赖任务
      tse_task_list_add(stask, &io_task_list) 加到io任务列表
    tse_task_list_sched(&io_task_list, false); 调度执行
    array_decref(array)
    tse_task_register_cbs(stask, check_short_read_cb 读回调
    tse_sched_progress(tse_task2sched(task)) 推进/处理


check_short_read_cb

通过以下对象连接
.cpf_name =
daos_opc_t
dc_funcs[opc].task_func 客户端方法数组

DAOS_OPC_OBJ_UPDATE 写
  dc_obj_update_task DAOS_OBJ_RPC_UPDATE
    obj_req_valid(task, args, DAOS_OBJ_RPC_UPDATE
      obj_auxi = tse_task_stack_push(task, sizeof(*obj_auxi))
      tse_task_stack_pop
    dc_tx_attach(args->th, obj, DAOS_OBJ_RPC_UPDATE, task) 如果事务有效(hdl.cookie == 1), 则走dtx
  dc_obj_update 否则
      obj_task_init_common(task, DAOS_OBJ_RPC_UPDATE
        tse_task_stack_push
        shard_task_list_init(obj_auxi)
      obj_rw_req_reassemb 重新组装
      dkey_hash = obj_dkey2hash
      obj_req_get_tgts 获取对象对应的目标
        obj_dkey2grpmemb
          obj_dkey2grpidx
            pool_map_ver = pool_map_get_version(pool->dp_map)
            grp_size = obj_get_grp_size(obj)
            grp_idx = d_hash_jump(hash, obj->cob_shards_nr / grp_size) how hash generate? obj with pool
        obj_shards_2_fwtgts
          obj_shard_tgts_query 分片目标查询
            obj_shard_open
              dc_obj_shard_open
                pool_map_find_target 二分查找
                  comp_sorter_find_target(sorter, id)
                    daos_array_find
                      array_bin_search
          obj_grp_leader_get
            pl_select_leader obj_get_shard
              array_bin_search 二分查找 daos_obj_classes
      tse_task_register_comp_cb(task, obj_comp_cb, NULL, 0)
      obj_csum_update(obj, args, obj_auxi)
      obj_rw_bulk_prep
      obj_req_fanout(obj, obj_auxi, dkey_hash, map_ver, epoch, shard_rw_prep, dc_obj_shard_rw, task)  扇出 shard_io_cb = io_cb = dc_obj_shard_rw


ds_obj_rw_handler 接收端的回调
  obj_ioc_begin 访问VOS前的各种检查
  obj_rpc_is_fetch
  process_epoch
  obj_rpc_is_fetch
  rc = dtx_begin 返回超时?
    dtx_handle_init
      dtx_shares_init(dth) 初始化以下链表, 提交,中断,活动,检查
      dtx_epoch_bound
      vos_dtx_rsrvd_init(dth)
  obj_local_rw 本地读写


创建任务, daos_task_create
创建一个异步任务并将其与 daos 客户端操作相关联。 对于同步操作，请为该操作使用特定的 API。 通常，此 API 用于需要将一系列 daos 操作排队到 DAOS 异步引擎中的用例，这些任务之间的执行顺序具有特定的依赖性。 例如，用户可以创建任务来打开一个对象，然后使用插入到打开任务更新中的依赖项来更新该对象。 对于更简单的工作流程，用户可以使用基于事件的 API 而不是任务。


dfuse_start
  dfuse_progress_thread


重要结构：

tse_task_t	*io_task = NULL; io任务






ubix:

pool_map
ufuse_cb_write position=0
  ufuse_cb_write_complete 回调
  ufs_write
    dc_array_write
    ubip_task_create UBIP_OPC_OBJ_UPDATE
    dc_obj_update_task
    dc_obj_update
      obj_update_shards_get
      obj_rw_bulk_prep
      obj_req_fanout shard_rw_prep dc_obj_shard_rw = shard_io_cb 请求扇出
        io_prep_cb shard_rw_prep 发送io前执行的回调
        shard_io 分片IO
          obj_shard_open
            map_ver
            dc_obj_shard_open 打开分片
            dc_cont_tgt_idx2ptr 根据容器handler和taget索引，获取池的目标pool_target
              pool
              dc_hdl2pool
                ubip_hhash_link_lookup(poh.cookie)
              pool_map_find_target
              dc_pool_put
                ubip_hhash_link_putref
              dc_cont_put
          shard_auxi->shard_io_cb(obj_shard,...) -> dc_obj_shard_rw 对象分片读写回调
          obj_shard_close



import struct
pool_target


main
ufuse_start
  ufuse_lanuch_fuse
    ll_loop_fn
      ufuse_loop
        start_one
          ufuse_do_work
            fuse_session_process_buf_int libfuse3.so.3
              do_write_buf(req, in->nodeid, inarg, buf)
                se->op.write_buf(req, nodeid, &bufv, arg->offset, &fi)
                ufuse_cb_write step?




dc_obj_shard_rw 客户端对象分片读写(读写对象分片)
  obj_shard_ptr2pool(shard) 根据分片获取池
  obj_req_create opc = UBIP_OBJ_RPC_UPDATE -> ds_obj_rw_handler
  uuid_copy
  ubip_dti_copy 拷贝dtx_id
  跳过ec逻辑
  tse_task_register_comp_cb
  ubip_rpc_send
    crt_req_send ubip_rpc_cb -> tse_task_complete 发送完成回调流程:hg -> crt_hg_req_send_cb -> crp_complete_cb -> -> ubip_rpc_cb -> dc_rw_cb

超时检测和业务回调是在不同的线程中并发执行

ds_obj_rw_handler
  obj_rw_reply
    obj_reply_set_status 与 obj_reply_get_status 成对使用
      ((struct obj_rw_out *)reply)->orw_ret = status 设置回复状态


怎么处理超时

crt_swim_cli_cb
ca_arrays


tse 调度
dc_task_create
  sched = daos_ev2sched(ev) 事件转调度器
  tse_task_create 初始化 tse_task。 该任务会被添加到调度器任务列表中，稍后被调度，如果提供了依赖任务，则该任务将被添加到依赖任务的dep列表中，一旦依赖任务完成，则添加该任务 到调度程序列表。
  task_ptr2args 指针转参数
    tse_task_buf_embedded 获取任务的嵌入式缓冲区，用户可以使用它来携带功能参数。 任务的嵌入式缓冲区有大小限制，如果 buf_size 大于限制，此函数将返回 NULL。 用户应通过 tse_task_set_priv() 使用私有数据来传递大参数。 MSC - 我将其更改为只是一个缓冲区，而不是像以前那样, 不断给一个额外的指针指向大的预涂层缓冲区。 以前的方式不适用于公共用途。我们现在应该使它更简单，更通用，如下面的评论
      tse_task_buf_size
        return (size + 7) & ~0x7
  tse_task_register_comp_cb(task, task_comp_event, NULL, 0) dtc->dtc_cb = cb task_comp_event 注册完成回调
    register_cb(task, true, comp_cb, arg, arg_size)
      d_list_add(&dtc->dtc_list, &dtp->dtp_comp_cb_list) 插入到列表开始处




执行任务的回调，如果所有的CB都执行完则返回true
并且不重新启动任务。 如果任务被用户重新初始化，则意味着
它又在飞行中，所以我们在重新初始化它的当前 CB 处中断，
并返回 false，表示任务未完成。 所有剩余的 CB
未执行的仍然附加，但已执行的
此时已经从列表中删除
tse_task_complete_callback
  ret = dtc->dtc_cb(task, dtc->dtc_arg); task_comp_event




crt_rpc_completed call 2？ 重复完成，duplicated completions

ubip_rpc_db
ubip_rpc_complete
  tse_task_complete
    tse_sched_process_complete(dsp)
      post_procee
        tse_task_complete_callback
          dtc_cb 执行注册时的回调 register_cb -> dc_rw_cb
          task_comp_event
            event_complete
              complete_locked
                ubip_event_complete_cb
                  d_list_for_each_entry_safe
                  d_list_del_init
                  __gurt_list_del

dc_rw_cb 
  opc_get
  UBIP_FAIL_CHECK
dc_obj_shard_rw
  tse_task_register_comp_cb(task, dc_rw_cb...)  dtc->dtc_cb = cb   <- tse_task_complete_callback
    dc_rw_cb
      rc = obj_reply_get_status  DER_SHUTDOWN(-2017) | DER_IO(-2001) 2008 NOTLEADER
        ((struct obj_rw_out *)reply)->orw_ret

dc_task_schedule
  task_is_valid
  daos_event_launch
  tse_task_schedule
    tse_task_schedule_with_delay 与 tse_task_schedule 相同，如果 instant 为 false，则期望任务不会在 delay 微秒内执行。

daos_event_comp_list 事件完成列表


dc_rw_cb DER_NO_HDL 'Invalid handle' 1002 追rc
  opc = OBJ_RPC_UPDATE = 0
  rc = obj_reply_get_status orw_ret




crt_ctx_epi_abort
  crt_rpc_complete


StorageFormat 在请求的主机列表中提供的所有主机或所有已配置的主机（如果未明确指定）并发执行存储准备步骤。 该函数会阻塞，直到收到所有结果（成功或失败），并返回一个包含所有主机存储准备操作结果的响应结构。
dmg storage format  Format SCM and NVMe storage attached to remote servers.
type storageFormatCmd struct
func (cmd *storageFormatCmd) Execute
  func StorageFormat
    checkFormatReq



dc_pool_query


daos_event_init
  D_CASSERT
  D_INIT_LIST_HEAD(&evx->evx_child);
	D_INIT_LIST_HEAD(&evx->evx_link);
	D_INIT_LIST_HEAD(&evx->evx_callback.evx_comp_list);
  eqx = daos_eq_lookup(eqh)
    hlink = daos_hhash_link_lookup(eqh.cookie)
      d_hhash_link_lookup(daos_ht.dht_hhash, key)
  daos_eq_putref(eqx)



daos_hhash_init_feats
  d_hhash_create dht_hhash


dfuse_fs_init
  daos_eq_create
    daos_eq_insert



读
dc_array_read
  dc_array_io DAOS_OPC_ARRAY_READ



读
dc_obj_fetch_task
  obj_req_valid 校验请求
  obj_task_init
  obj_req_with_cond_flags
    obj_cond_fetch_prep 预处理, 将 obj 任务拆分为多个子任务
  obj_fetch_shards_get
  obj_shards_2_fwtgts
  obj_csum_fetch
  obj_rw_bulk_prep
  obj_req_fanout shard_rw_prep dc_obj_shard_rw 请求扇出


重复完成 coredump
dfuse_ops
.lookup		= df_ll_lookup 按名称查找目录条目并获取其属性
df_ll_lookup
  // 查inodes表
  d_hash_rec_find(&fs_handle->dpi_iet, &parent, sizeof(parent))  d_hash_rec_insert(&fs_handle->dpi_iet 插入hash表
  parent_inode->ie_dfs->dfs_ops->lookup(req, parent_inode, name) 调用父节点的查找方法
    dfuse_cb_lookup
  d_hash_rec_decref(&fs_handle->dpi_iet, rlink)

ufuse_cb_getattr 先获取属性
dfuse_dfs_ops
.lookup		= dfuse_cb_lookup
分配ie
dfs_lookupx 查询条目,获取属性, 生成?
  dfs_lookup_rel_int
    check_name 检查文件名和文件名长度
    get_daos_obj_mode 返回对象模式, 只读|读写
    fetch_entry 获取条目/查条目
      d_iov_set(&dkey, (void *)name, len)
      d_iov_set(&iod->iod_name, INODE_AKEY_NAME
      DAOS_IOD_ARRAY
      sgl->sg_iovs	= sg_iovs
      daos_obj_fetch 从数组中查询对象 ioms: 存储缓冲层(接收缓冲区)
        dc_obj_fetch_task_create 创建获取任务
          DAOS_API_ARG_ASSERT(*args, OBJ_FETCH) 通过断言检查参数预定义大小和传入的参数大小
          dc_task_create(dc_obj_fetch_task, tse, ev, task) dc_obj_fetch_task -> func -> task_func -> dtp_func daos任务私有回调
            daos_event_priv_get(&ev) 获取基于线程的私有事件, static __thread daos_event_t	ev_thpriv; 线程私有数据
            sched = daos_ev2sched(ev)
            tse_task_create
        dc_task_schedule
    switch (entry.mode & S_IFMT) 判断条目类型 文件,符号链接, 
      daos_array_open_with_attr 普通文件 S_IFREG
        dc_array_open
          daos_task_create(DAOS_OPC_OBJ_OPEN 创建对象打开任务, 创建一个异步任务并将其与 daos 客户端操作相关联。 对于同步操作，请为该操作使用特定的 API。 通常，此 API 用于需要将一系列 daos 操作排队到 DAOS 异步引擎中的用例，这些任务之间的执行顺序具有特定的依赖性。 例如，用户可以创建任务来打开一个对象，然后使用插入到打开任务更新中的依赖项来更新该对象。 对于更简单的工作流程，用户可以使用基于事件的 API 而不是任务
          tse_task_register_deps 注册依赖任务
            for num_deps 遍历依赖任务数量
              tse_task_add_dependent(task, dep_tasks[i])
                Add dependent 依赖 -> 主任务
                  d_list_add_tail(&tlink->tl_link, &dep_dtp->dtp_dep_list) 添加到依赖链表
          tse_task_register_comp_cb(task, open_handle_cb 注册打开完成回调
          tse_task_schedule(open_task, false) 调度任务
          tse_sched_progress(tse_task2sched(task)) 推进任务
          daos_task_create(DAOS_OPC_OBJ_FETCH 查看元数据
atomic_store_relaxed(&ie->ie_ref, 1); 初始化引用计数 原子操作
dfs_obj2id 文件系统转daos对象 128位(32+96)
dfuse_compute_inode
S_ISDIR 目录
  check_for_uns_ep 统一命名空间
dfuse_reply_entry

io故障

打开回调
open_handle_cb
  open_with_attr = 1
  array_hdl_link(array) 
  *args->oh = array_ptr2hdl(array)
    ubip_hhash_link_lookup(oh.cookie) 根据key查找hash表


dc_array_set_size


0x00001 ----> oh



dc_array_get_size
dc_array_stat
DAOS_OPC_OBJ_QUERY_KEY DAOS_OBJ_RPC_QUERY_KEY
dc_obj_query_key
  obj_task_init(api_task, DAOS_OBJ_RPC_QUERY_KEY
  queue_shard_query_key_task
    shard_query_key_task // 客户端pool map err
    dc_obj_shard_query_key
      obj_shard_query_key_cb


opc=0x4090009 DAOS_OBJ_RPC_QUERY_KEY 查键
ds_obj_query_key_handler_1

全局rpc操作码: cg_opc_map


open shard
obj_shard_open 18


shard_query_key_task

daos_task_create(DAOS_OPC_OBJ_QUERY_KEY


dc_obj_open_task_create
  dc_task_create(dc_obj_open, "obj open")
  


obj_rw_req_reassemb 重新组装对象读写请求


